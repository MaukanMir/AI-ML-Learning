{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Training Jobs with Amazon SageMaker Debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring a training job to use SageMaker Debugger\n",
    "\n",
    "#### The first step is to configure training jobs to use Amazon SageMaker Debugger. By now, you are familiar with using the Estimator object from SageMaker SDK to launch training jobs. To use Amazon SageMaker Debugger, you must enhance Estimator with three additional configuration parameters: DebuggerHookConfig, Rules, and ProfilerConfig\n",
    "\n",
    "#### With DebuggerHookConfig, you can specify which debugging metrics to collect and where to store them, as shown in the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimator(\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=bucket_path,  # Where the debug data is stored.\n",
    "        collection_configs=[ # Organize data to collect into collections.\n",
    "            CollectionConfig(\n",
    "                name=\"metrics\",\n",
    "                parameters={\n",
    "                    \"save_interval\": str(save_interval)\n",
    "                }\n",
    "            )\n",
    "        ],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s3_output_path is the location where all the collected data is persisted. If this location is not specified, Debugger uses the default path, s3://<output_path>/debug-output/, where <output_path>Â is the output path of the SageMaker training job. The CollectionConfig list allows you to organize the debug data or tensors into collections for easier analysis. A tensor represents the state of a training network at a specific time during the training process. Data is collected at intervals, as specified by save_interval, which is the number of steps in a training run.\n",
    "\n",
    "#### How do you know which tensors to collect? SageMaker Debugger comes with a set of built-in collections to capture common training metrics such as weights, layers, and outputs. You can choose to collect all of the available tensors or a subset of them. In the preceding code sample, Debugger is gathering the metrics collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Debugger CollectionConfig to create a custom collection\n",
    "\n",
    "collection_configs=[\n",
    "        CollectionConfig(\n",
    "            name=\"custom_collection\",\n",
    "            parameters={\"include_regex\": \".*relu |.*tanh | *weight \",})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While DebuggerHookConfig allows you to configure and save tensors, a rule analyzes the tensors that are captured during the training for specific conditions such as loss not decreasing. SageMaker Debugger supports two different types of rules: built-in and custom. SageMaker Debugger comes with a set of built-in rules in Python that can detect and report common training problems such as overfitting, underfitting, and vanishing gradients. With custom rules, you write your own rules in Python for SageMaker Debugger to evaluate against the collected tensors.\n",
    "\n",
    "#### For example, in the following code block, Debugger collects tensors related to the metrics collection and evaluates the tensors to detect whether the training loss is reduced throughout the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimator(\n",
    "rules=[\n",
    "        Rule.sagemaker(\n",
    "            rule_configs.loss_not_decreasing(),\n",
    "            rule_parameters={\n",
    "                \"collection_names\": \"metrics\",\n",
    "                \"num_steps\": str(save_interval * 2),\n",
    "            },\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, ProfilerConfig allows you to collect system metrics such as CPU, GPU, Memory, I/O, and framework metrics specific to the framework being used in your training job. For the system metrics, you must specify the time interval for which you want to collect metrics, while for framework metrics, you specify the starting step and the number of steps, as shown in the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimator(\n",
    "    profiler_config = ProfilerConfig(\n",
    "    ## Monitoring interval in milliseconds\n",
    "    system_monitor_interval_millis=500)\n",
    "    ## Start collecting metrics from step 2 and collect from the next 7 steps.\n",
    "    framework_profile_params=FrameworkProfile(\n",
    "    start_step=2,\n",
    "    num_steps=7\n",
    "))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
