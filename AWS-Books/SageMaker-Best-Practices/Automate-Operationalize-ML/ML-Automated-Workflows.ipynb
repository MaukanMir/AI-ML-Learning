{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Automated Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we'll enable step caching. Step caching tells SageMaker to check for a previous execution of a step that was called with the same arguments. This is so that it can use the previous step values of a successful run instead of re-executing a step with the exact same arguments. You should consider using step caching to avoid unnecessary tasks and costs. As an example, if the second step (model training) in your pipeline fails, you can start the pipeline again without re-executing the data preparation step if that step has not changed, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"T360m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll define the runtime arguments using the get_run_args method. In this case, we are passing the Spark processor that was previously configured, in combination with the parameters identifying the inputs (raw weather data), the outputs (train, test, and validation datasets), and additional arguments the data processing script accepts as input. The data processing script, preprocess.py, is a slightly modified version of the processing script used in Chapter 4, Data Preparation at Scale Using Amazon SageMaker Data Wrangler and Processing. Refer to the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "run_args = pyspark_processor.get_run_args(\n",
    "    \"preprocess.py\",\n",
    "    submit_jars=[\"s3://crawler-public/json/serde/json-serde.jar\"],\n",
    "    spark_event_logs_s3_uri=spark_event_logs_s3_uri,\n",
    "    configuration=configuration,\n",
    "    outputs=[ \\\n",
    "        ProcessingOutput(output_name=\"validation\", destination=validation_data_out, source=\"/opt/ml/processing/validation\"),\n",
    "\n",
    "        ProcessingOutput(output_name=\"train\", destination=train_data_out, source=\"/opt/ml/processing/train\"),\n",
    "\n",
    "        ProcessingOutput(output_name=\"test\", destination=test_data_out, source=\"/opt/ml/processing/test\"),\n",
    "     ],\n",
    "    arguments=[\n",
    "        '--s3_input_bucket', s3_bucket,\n",
    "        '--s3_input_key_prefix', s3_prefix_parquet,\n",
    "        '--s3_output_bucket', s3_bucket,\n",
    "        '--s3_output_key_prefix', s3_output_prefix+'/prepared-data/'+timestamp\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll use the runtime parameters to configure the actual SageMaker Pipelines step for our data preprocessing tasks. You'll notice we're using all of the parameters we configured previously to build the step that will execute as part of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"DataPreparation\",\n",
    "    processor=pyspark_processor,\n",
    "    inputs=run_args.inputs,\n",
    "    outputs=run_args.outputs,\n",
    "    job_arguments=run_args.arguments,\n",
    "    code=\"modelbuild/pipelines/preprocess.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we'll configure the SageMaker training job, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"5\"}\n",
    "\n",
    "# set an output path where the trained model will be saved\n",
    "m_prefix = 'pipeline/model'\n",
    "output_path = 's3://{}/{}/{}/output'.format(s3_bucket, m_prefix, 'xgboost')\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "image_uri = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_uri=image_uri,\n",
    "                         hyperparameters=hyperparameters,\n",
    "                     role=sagemaker.get_execution_role(),\n",
    "                         instance_count=1,\n",
    "                         instance_type='ml.m5.12xlarge',\n",
    "                         volume_size=200, # 5 GB\n",
    "                         output_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll configure the SageMaker Pipelines step that will be used to execute your model training task. For this, we'll use the built-in training step (https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training). This tells Pipelines this step will be a SageMaker training job. Figure 12.6 shows the high-level inputs and outputs/artifacts that a Training step will expect:\n",
    "\n",
    "#### We previously configured the estimator, so we will now use that estimator combined with the other inputs shown in Figure 12.6 to set up our Pipelines step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"ModelTrain\",\n",
    "    estimator=xgb_estimator,\n",
    "    cache_config=cache_config,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation step\n",
    "\n",
    "#### In this step, you'll configure a SageMaker processing job that will be used to evaluate your trained model using the model artifact produced from the training step in combination with your processing code and configuration:\n",
    "\n",
    "#### First, we'll configure the SageMaker processing job starting with ScriptProcessor. We will use this to execute a simple evaluation script, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-weather-eval\",\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll configure the SageMaker Pipelines step that will be used to execute your model evaluation tasks. For this, we'll use the built-in Processing step (https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing). This tells Pipelines this step will be a SageMaker processing job. \n",
    "\n",
    "#### We previously configured the processor, so we will now use that processor combined with the other inputs shown in Figure 12.7 to set up our Pipelines step. To do this, we'll first set up the property file that will be used to store the output, in this case, model evaluation metrics, of our processing job. Then, we'll configure the ProcessingStep definition as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"WeatherEval\",\n",
    "    processor=script_eval,\n",
    "    cache_config = cache_config,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "          source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,  destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"modelbuild/pipelines/evaluation.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional step\n",
    "\n",
    "#### In this step, you'll configure a built-in conditional step that will determine whether to proceed to the next step in the pipeline based on the results of your previous model evaluation step. Setting up a conditional step requires a list of conditions or items that must be true. This is in combination with instructions on the list of steps to execute based on that condition.\n",
    "\n",
    "#### In this case, we're going to set up a condition using the mean squared error (MSE) metric. If the metric is less than or equal to nn, then we will indicate the steps to proceed with using the if_steps parameter. In this case, the next steps if the condition were true would be to register the model and then create the model that packages your model for deployment. You can optionally specify else_steps to indicate the next steps to perform if the condition is not true. In this case, we will simply terminate the pipeline if the condition is not true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet\n",
    ")\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\"\n",
    "    ),\n",
    "    right=6.0\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"MSECondition\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register, step_create_model],\n",
    "    else_steps=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model step(s)\n",
    "\n",
    "#### In this final step, you'll package the model and configure a built-in register model (https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-register-model) step that will register your model to a model package group in SageMaker model registry. As seen in Figure 12.9, the inputs we'll use to register the model contain information about the packaged model, such as the model version, estimator, and S3 location of the model artifact. This information, when combined with additional information such as model metrics and inference specifications, is used to register the model version:\n",
    "\n",
    "#### This step will use data from the prior steps in the pipeline to register the model and centrally store key metadata about this specific model version. In addition, you'll see an approval_status parameter. This parameter can be used to trigger downstream deployment processes (these will be discussed in more detail under SageMaker Projects):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "    s3_uri=\"{}/evaluation.json\".format(\n",
    "\n",
    "step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
