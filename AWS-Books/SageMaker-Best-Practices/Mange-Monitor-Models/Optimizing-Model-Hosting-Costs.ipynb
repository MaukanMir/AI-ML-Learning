{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Model Hosting and Inference Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time inference versus batch inference\n",
    "#### SageMaker provides two ways to obtain inferences:\n",
    "\n",
    "- Real-time inference lets you get a single inference per request, or a small number of inferences, with very low latency from a live inference endpoint.\n",
    "- Batch inference lets you get a large number of inferences from a batch processing job.\n",
    "\n",
    "#### Batch inference is more efficient and more cost-effective. Use it whenever your inference requirements allow. We'll explore batch inference first, and then pivot to real-time inference.\n",
    "\n",
    "## Batch inference\n",
    "\n",
    "#### In many cases, we can make inferences in advance and store them for later use. For example, if you want to generate product recommendations for users on an e-commerce site, those recommendations may be based on the users' prior purchases and which products you want to promote the next day. You can generate the recommendations nightly and store them for your e-commerce site to call up when the users browse the site.\n",
    "\n",
    "#### There are several options for storing batch inferences. Amazon DynamoDB is a common choice for several reasons, such as the following:\n",
    "\n",
    "- It is fast. You can look up single values within a few milliseconds.\n",
    "- It is scalable. You can store millions of values at a low cost.\n",
    "- The best access pattern for DynamoDB is looking up values by a high-cardinality primary key. This fits well with many inference usage patterns, for example, when we want to look up a stored recommendation for an individual user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input = \"s3://{}/{}/{}/\".format(s3_bucket, s3_prefix, 'test')\n",
    "batch_output = \"s3://{}/{}/{}/\".format(s3_bucket, \"xgboost-sample\", 'xform')\n",
    "transformer = estimator.transformer(instance_count=1,\n",
    "instance_type='ml.m5.4xlarge', output_path=batch_output, max_payload=3)\n",
    "transformer.transform(data=batch_input, data_type='S3Prefix',\n",
    "content_type=content_type, split_type='Line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
