{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Model Hosting and Inference Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time inference versus batch inference\n",
    "#### SageMaker provides two ways to obtain inferences:\n",
    "\n",
    "- Real-time inference lets you get a single inference per request, or a small number of inferences, with very low latency from a live inference endpoint.\n",
    "- Batch inference lets you get a large number of inferences from a batch processing job.\n",
    "\n",
    "#### Batch inference is more efficient and more cost-effective. Use it whenever your inference requirements allow. We'll explore batch inference first, and then pivot to real-time inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
