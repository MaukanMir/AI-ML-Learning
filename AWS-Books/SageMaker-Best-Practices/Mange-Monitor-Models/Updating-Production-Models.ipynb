{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating Production Models Using Amazon SageMaker Endpoint Production Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A deployed production model needs to be updated for a variety of reasons, such as to gain access to new training data, to experiment with a new algorithm and hyperparameters, or to model predictive performance deteriorating over time. Any time you update a model with a new version in production, there is a risk of the model becoming unavailable during the update and the model's quality being worse than the previous version. Even after careful evaluation in the development and QA environments, new models need additional testing, validation, and monitoring to make sure they work properly in production.\n",
    "\n",
    "#### As the SageMaker Endpoints are serving inference traffic, they are monitored using Amazon CloudWatch Metrics. Use the EndpointName and VariantName dimensions to monitor metrics for each distinct production variant of the same endpoint. The Invocations metric captures the number of requests that are sent to a model, as indicated by the production variant. You can use this metric to monitor the number of requests that are served by different models and deployed with a single endpoint.\n",
    "\n",
    "#### Similar to Production Variants, SageMaker multi-model endpoints (MME) also allow us to host multiple models on a single endpoint. If that is the case, how are Production Variants different from multi-model endpoints?\n",
    "\n",
    "#### With an MME, all models are hosted on the same compute infrastructure. However, not all the models are loaded into the container memory when the endpoint is created. Instead, the model is loaded into memory when an inference request is made. Each inference request must specify the model to invoke. The invoked model is then loaded into memory from the S3 bucket if it is not already in memory. Depending on the invocation pattern, a model that hasn't been invoked recently may not be in memory. This could result in increased latency when serving the request. When you have a large number of similar ML models that are infrequently accessed and can tolerate slightly increased latency, then a single MME can serve inference traffic at significantly low costs.\n",
    "\n",
    "#### On the other hand, with Production Variants, each model is hosted on a completely different compute infrastructure, and all the models are readily available without having to be loaded into container memory on demand. Each inference request may or may not specify the variant to invoke. If the variant to invoke is not specified, the number of inference requests that are served by each variant depends on the initial_weight parameter of the production variant. In the context of model deployment, use Production Variants to test different versions of ML models that have been trained using different datasets, algorithms, and ML frameworks or to test how a model performs on different instance types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Set up\n",
    "- Prepare (Reuse or Train) models to deploy and update\n",
    "- Create an endpoint (with single production variant)\n",
    "- Invoke the endpoint\n",
    "- Update endpoint (with two production variants)\n",
    "- CloudWatch Analysis\n",
    "- Update endpoint\n",
    "- Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Imports\n",
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.session import production_variant\n",
    "from botocore.response import StreamingBody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = 'datascience-environment-notebookinstance--06dc7a0224df'\n",
    "s3_prefix = 'prepared'\n",
    "m_prefix = 'xgboost-sample'\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Setup service clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.Session().client(\"sagemaker\")\n",
    "smrt = boto3.Session().client(\"sagemaker-runtime\")\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "### Define variable to toggle between using trained models from previous chapters and training the models in this notebook\n",
    "\n",
    "### Set use_trained_models to True, if you have XGBoost models trained in previous chapters, use those models to save training time and costs.\n",
    "### To train models in this notebook set use_trained_model to False.\n",
    "#use_trained_models = 'False'\n",
    "use_trained_models = 'True'\n",
    "\n",
    "if use_trained_models == 'True':\n",
    "    print(\"Using models trained before\")\n",
    "else:\n",
    "    print(\"Train the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Prepare (Reuse or Train) models to deploy and update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the XGBoost models previously trained\n",
    "### Note: Update to use the models available in your datascience account\n",
    "if use_trained_models == 'True':\n",
    "    model_name_1='sagemaker-xgboost-2021-06-24-02-34-20-510'\n",
    "    model_name_2='sagemaker-xgboost-2021-06-24-02-47-08-912'\n",
    "\n",
    "if use_trained_models == 'False':\n",
    "\n",
    "    # set an output path where the trained model will be saved\n",
    "    output_path = 's3://{}/{}/{}/output'.format(s3_bucket, m_prefix, 'xgboost')\n",
    "    \n",
    "    # this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "    # specify the repo_version depending on your preference.\n",
    "    xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "    \n",
    "    # define the data type and paths to the training and validation datasets\n",
    "    content_type = \"csv\"\n",
    "    train_input = TrainingInput(\"s3://{}/{}/{}/\".format(s3_bucket, s3_prefix, 'train'), content_type=content_type)\n",
    "    validation_input = TrainingInput(\"s3://{}/{}/{}/\".format(s3_bucket, s3_prefix, 'validation'), content_type=content_type)\n",
    "\n",
    "    #### Train and get the name of the first model \n",
    "    # initialize hyperparameters\n",
    "    hyperparameters_1 = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"5\"}\n",
    "\n",
    "    # construct a SageMaker estimator that calls the xgboost-container\n",
    "    estimator_1 = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters_1,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.12xlarge', \n",
    "                                          volume_size=200, # 5 GB \n",
    "                                          output_path=output_path)\n",
    "\n",
    "\n",
    "    # execute the XGBoost training job\n",
    "    estimator_1.fit({'train': train_input, 'validation': validation_input})\n",
    "    \n",
    "    training_job_name_1 = estimator_1.latest_training_job.name\n",
    "    \n",
    "    model_name_1 = sagemaker_session.create_model_from_job(training_job_name_1)\n",
    "    \n",
    "    \n",
    "    #### Train and get the name of the second model \n",
    "    # initialize hyperparameters\n",
    "    hyperparameters_2 = {\n",
    "        \"max_depth\":\"10\",  ##Different value of the hyperparameter\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"5\"}\n",
    "\n",
    "    # construct a SageMaker estimator that calls the xgboost-container\n",
    "    estimator_2 = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters_2,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.12xlarge', \n",
    "                                          volume_size=200, # 5 GB \n",
    "                                          output_path=output_path)\n",
    "\n",
    "\n",
    "    # execute the XGBoost training job\n",
    "    estimator_2.fit({'train': train_input, 'validation': validation_input})\n",
    "    \n",
    "    training_job_name_2 = estimator_2.latest_training_job.name\n",
    "    \n",
    "    model_name_2 = sagemaker_session.create_model_from_job(training_job_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model 1 : \" , model_name_1)\n",
    "print(\"Model 2 : \" , model_name_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Create an endpoint (with single production variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create production variant A\n",
    "variantA = production_variant(model_name=model_name_1,\n",
    "                              instance_type=\"ml.m5.xlarge\",\n",
    "                              initial_instance_count=1,\n",
    "                              variant_name='VariantA',\n",
    "                              initial_weight=1)\n",
    "\n",
    "#Variable for endpoint name\n",
    "endpoint_name=f\"abtest-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "##First create an endpoint with single variant\n",
    "##Note this step automatically creates an endpointconfig with same name as the endpoint, that you can update later\n",
    "\n",
    "#Create an endpoint with a single production variant\n",
    "sagemaker_session.endpoint_from_production_variants(\n",
    "    name=endpoint_name,\n",
    "    production_variants=[variantA]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Invoke the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get the file name at index from the 'prefix' folder\n",
    "def get_file_in_bucket(prefix,index):\n",
    "    response = s3.list_objects(\n",
    "        Bucket=s3_bucket,\n",
    "        Prefix=s3_prefix + \"/\" + prefix\n",
    "    )\n",
    "    ## At '0' index you will find the SUCCESS/FAILURE of file uploades to S3. First data file is at index 1\n",
    "    file_name = response['Contents'][index]['Key']\n",
    "    print(\"Returing file name : \" + file_name)\n",
    "    return file_name\n",
    "\n",
    "##Download the test files to execute inferences\n",
    "s3.download_file(s3_bucket, get_file_in_bucket('test',1), 't_file.csv')\n",
    "\n",
    "with open('t_file.csv', 'r') as TF:\n",
    "    t_lines = TF.readlines()\n",
    "\n",
    "### Define a method to run inferences against the endpoint\n",
    "def get_predictions():\n",
    "    #Skip the first line since it has column headers\n",
    "    for tl in t_lines[1:50]:\n",
    "        #Remove the first column since it is the label\n",
    "        test_list = tl.split(\",\")\n",
    "        test_list.pop(0)\n",
    "        test_string = ','.join([str(elem) for elem in test_list])\n",
    "    \n",
    "        result = smrt.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType=\"text/csv\",\n",
    "                                   Body=test_string)\n",
    "        #print(result)                              \n",
    "        rbody = StreamingBody(raw_stream=result['Body'],content_length=int(result['ResponseMetadata']['HTTPHeaders']['content-length']))\n",
    "        print(f\"Result from {result['InvokedProductionVariant']} = {rbody.read().decode('utf-8')}\")\n",
    "\n",
    "#Get predictions\n",
    "get_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Update endpoint with two production variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create production variant B\n",
    "variantB = production_variant(model_name=model_name_2,\n",
    "                              instance_type=\"ml.m5.xlarge\",\n",
    "                              initial_instance_count=1,\n",
    "                              variant_name='VariantB',\n",
    "                              initial_weight=1)\n",
    "\n",
    "##Next update the endpoint to include both production variants\n",
    "endpoint_config_new =f\"abtest-new-config-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "sagemaker_session.create_endpoint_config_from_existing (\n",
    "    existing_config_name=endpoint_name,\n",
    "    new_config_name=endpoint_config_new,\n",
    "    new_production_variants=[variantA,variantB]  ## Two production variants\n",
    ")\n",
    "\n",
    "##Update the endpoint\n",
    "sagemaker_session.update_endpoint(endpoint_name=endpoint_name, endpoint_config_name=endpoint_config_new, wait=False)\n",
    "#Show that you can still get inferences while the endpoint is being updated\n",
    "#Get predictions\n",
    "get_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CloudWatch Analysis\n",
    "#### Observe the CloudWatch metrics generated for the two variants to understand the endpoint behavior. Here we are plotting the number of invocations of each variant. You can use the same pattern to plot other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define utility methods to retrieve and plot cloudwatch metrics\n",
    "import pandas as pd\n",
    "\n",
    "cw = boto3.Session().client(\"cloudwatch\")\n",
    "\n",
    "def get_invocation_metrics_for_endpoint_variant(endpoint_name, variant_name, start_time, end_time):\n",
    "    metrics = cw.get_metric_statistics(\n",
    "        Namespace=\"AWS/SageMaker\",\n",
    "        MetricName=\"Invocations\",\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=[\"Sum\"],\n",
    "        Dimensions=[\n",
    "            {\"Name\": \"EndpointName\", \"Value\": endpoint_name},\n",
    "            {\"Name\": \"VariantName\", \"Value\": variant_name},\n",
    "        ],\n",
    "    )\n",
    "    return (\n",
    "        pd.DataFrame(metrics[\"Datapoints\"])\n",
    "        .sort_values(\"Timestamp\")\n",
    "        .set_index(\"Timestamp\")\n",
    "        .drop(\"Unit\", axis=1)\n",
    "        .rename(columns={\"Sum\": variant_name})\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_endpoint_metrics(start_time=None):\n",
    "    start_time = start_time or datetime.now() - timedelta(minutes=60)\n",
    "    end_time = datetime.now()\n",
    "    metrics_variant1 = get_invocation_metrics_for_endpoint_variant(\n",
    "        endpoint_name, variantA[\"VariantName\"], start_time, end_time\n",
    "    )\n",
    "    metrics_variant2 = get_invocation_metrics_for_endpoint_variant(\n",
    "        endpoint_name, variantB[\"VariantName\"], start_time, end_time\n",
    "    )\n",
    "    metrics_variants = metrics_variant1.join(metrics_variant2, how=\"outer\")\n",
    "    metrics_variants.plot()\n",
    "    return metrics_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Send traffic to endpoint for about 2 minutes.  \n",
    "##You should see both the variants serving traffic, after the endpoint is updated.\n",
    "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "#Skip the first line since it has column headers\n",
    "for tl in t_lines[1:200]:\n",
    "    #print(\".\", end=\"\", flush=True)\n",
    "    #Remove the first column since it is the label\n",
    "    test_list = tl.split(\",\")\n",
    "    test_list.pop(0)\n",
    "    test_string = ','.join([str(elem) for elem in test_list])\n",
    "    \n",
    "    result = smrt.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType=\"text/csv\",\n",
    "                                   Body=test_string)\n",
    "    #print(result)                              \n",
    "    rbody = StreamingBody(raw_stream=result['Body'],content_length=int(result['ResponseMetadata']['HTTPHeaders']['content-length']))\n",
    "    print(f\"Result from {result['InvokedProductionVariant']} = {rbody.read().decode('utf-8')}\")\n",
    "    time.sleep(0.5)  \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting a minute for initial metric creation...\")\n",
    "time.sleep(60)\n",
    "plot_endpoint_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Update endpoint to contain just the VariantB\n",
    "\n",
    "#### 7.1 - Gradually update the weights of each production variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the product variant weight to route 60% of traffic to VariantB\n",
    "sm.update_endpoint_weights_and_capacities(\n",
    "    EndpointName=endpoint_name,\n",
    "    DesiredWeightsAndCapacities=[\n",
    "        {\"DesiredWeight\": 4, \"VariantName\": variantA[\"VariantName\"]},\n",
    "        {\"DesiredWeight\": 6, \"VariantName\": variantB[\"VariantName\"]},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 - Alternatively, update the endpoint to route all live traffic to VariantB in a single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Update the endpoint to point to VariantB\n",
    "endpoint_config_new =f\"abtest-b-config-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "sagemaker_session.create_endpoint_config_from_existing (\n",
    "    existing_config_name=endpoint_name,\n",
    "    new_config_name=endpoint_config_new,\n",
    "    new_production_variants=[variantB]\n",
    ")\n",
    "\n",
    "##Update the endpoint\n",
    "##Note : This step will fail if the endpoint is still updating\n",
    "sagemaker_session.update_endpoint(endpoint_name=endpoint_name, endpoint_config_name=endpoint_config_new, wait=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not plan to use this endpoint further, you should delete the endpoint to avoid incurring additional charges.\n",
    "sagemaker_session.delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
