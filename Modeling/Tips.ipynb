{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "### A Machine Learning Specialist has created a neural network model for an image classification task. The Specialist encountered an overfitting issue wherein the validation loss is much greater than the training loss. Which action would MOST likely solve the problem and how should the Specialist justify it?\n",
    "\n",
    "- The option that says: The model is not generalizing well because itâ€™s not complex enough, therefore, additional nodes should be added at the hidden layer is incorrect. Overfitting means the model is already complex. Therefore, this would cause the model to overfit more.\n",
    "\n",
    "- Dropout is a technique that addresses this issue. It prevents overfitting and provides a way of approximately combining exponentially many different neural network architectures efficiently. The term dropout refers to dropping out units (hidden and visible) in a neural network. Hence, the correct answer is: Since the model is not generalizing well, he should increase the dropout rate at the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "### After training a SageMaker XGBoost based model over a huge training dataset, the data science team observed that it has low accuracy on the training data as well as low accuracy on the test data.As an AWS Certified ML Specialist, which of the following techniques would you recommend to help resolve this problem? (Select two):\n",
    "\n",
    "- Add regularization to the model\n",
    "- Use more training data\n",
    "- Use more features in the model\n",
    "- Remove regularization from the model\n",
    "- Use less features in the model\n",
    "\n",
    "\n",
    "### Use More Features in the Model\n",
    "\n",
    "- Rationale: Adding more features can provide the model with more information and potentially capture more complexity in the dataset. If the model is currently not performing well because it's too simplistic, increasing the number and variety of features might help it learn better and make more accurate predictions.\n",
    "- Impact: By introducing more relevant features, you allow the model to make decisions based on a wider array of data points, which might capture relationships and patterns previously overlooked."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
