{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "### A Machine Learning Specialist has created a neural network model for an image classification task. The Specialist encountered an overfitting issue wherein the validation loss is much greater than the training loss. Which action would MOST likely solve the problem and how should the Specialist justify it?\n",
    "\n",
    "- The option that says: The model is not generalizing well because itâ€™s not complex enough, therefore, additional nodes should be added at the hidden layer is incorrect. Overfitting means the model is already complex. Therefore, this would cause the model to overfit more.\n",
    "\n",
    "- Dropout is a technique that addresses this issue. It prevents overfitting and provides a way of approximately combining exponentially many different neural network architectures efficiently. The term dropout refers to dropping out units (hidden and visible) in a neural network. Hence, the correct answer is: Since the model is not generalizing well, he should increase the dropout rate at the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
