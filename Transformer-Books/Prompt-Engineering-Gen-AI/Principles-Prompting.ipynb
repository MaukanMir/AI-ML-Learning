{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the Five Principles of Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The process for optimizing this prompt follows the Five Principles of Prompting, which we will dissect using this example in the remainder of this chapter, and recall throughout the book. They map exactly to the five issues we raised when discussing the naive text prompt. You’ll find references back to these principles throughout the rest of the book to help you connect the dots to how they’re used in practice. The Five Principles of Prompting are as follows:\n",
    "\n",
    "#### Give Direction\n",
    "- Describe the desired style in detail, or reference a relevant persona\n",
    "\n",
    "#### Specify Format\n",
    "- Define what rules to follow, and the required structure of the response\n",
    "\n",
    "#### Provide Examples\n",
    "- Insert a diverse set of test cases where the task was done correctly\n",
    "\n",
    "#### Evaluate Quality\n",
    "- Identify errors and rate responses, testing what drives performance.\n",
    "\n",
    "#### Divide Labor\n",
    "- Split tasks into multiple steps, chained together for complex goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give Direction\n",
    "\n",
    "- One of the issues with the naive text prompt discussed earlier was that it wasn’t briefing the AI on what types of product names you wanted. To some extent, naming a product is a subjective endeavor, and without giving the AI an idea of what names you like, it has a low probability of guessing right.\n",
    "\n",
    "#### Example\n",
    "- Please give me 5 tips for naming products based on expert\n",
    "industry advice.\n",
    "\n",
    "#### Certainly! Naming a product is crucial as it often gives the first impression to potential customers. Here are five expert tips to guide you in naming products:\n",
    "\n",
    "1. **Simplicity & Memorability**: Opt for names that are\n",
    "short, easy to spell, and memorable. Long, complicated names\n",
    "can be difficult for customers to recall. Remember, the\n",
    "easier the name is to remember, the more likely it is that\n",
    "consumers will think of your product when making a purchase\n",
    "decision.\n",
    "\n",
    "...\n",
    "\n",
    "5. **Positive Connotations**: Names that evoke positive\n",
    "emotions or imagery can create a favorable perception of\n",
    "your product. Avoid names that have negative or\n",
    "controversial associations in any of the primary languages\n",
    "or cultures where you intend to do business. It's often\n",
    "worthwhile to conduct linguistic checks and market testing\n",
    "to ensure there aren't unintended meanings.\n",
    "\n",
    "Lastly, once you've shortlisted a few names, it's a good\n",
    "idea to run them by diverse focus groups or conduct surveys\n",
    "to gauge reactions. Also, ensure that the name you choose is\n",
    "available for trademarking and doesn't infringe on existing\n",
    "trademarks.\n",
    "\n",
    "#### Then within the same chat window, where the model has the context of the past advice it gave, you ask your initial prompt for the task you wanted to complete.\n",
    "\n",
    "- Using this advice, can I have a list of product names for a\n",
    "pair of shoes that can fit any foot size?\n",
    "\n",
    "#### Direction is one of the most commonly used and broadest principles. It can take the form of simply using the right descriptive words to clarify your intent, or channeling the personas of relevant business celebrities. While too much direction can narrow the creativity of the model, too little direction is the more common problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Format\n",
    "#### AI models are universal translators. Not only does that mean translating from French to English, or Urdu to Klingon, but also between data structures like JSON to YAML, or natural language to Python code. These models are capable of returning a response in almost any format, so an important part of prompt engineering is finding ways to specify what format you want the response to be in.\n",
    "\n",
    "#### Every now and again you’ll find that the same prompt will return a different format, for example, a numbered list instead of comma separated. This isn’t a big deal most of the time, because most prompts are one-offs and typed into ChatGPT or Midjourney. However, when you’re incorporating AI tools into production software, occasional flips in format can cause all kinds of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is often some overlap between the first and second principles, Give Direction and Specify Format. The latter is about defining what type of output you want, for example JSON format, or the format of a stock photo. The former is about the style of response you want, independent from the format, for example product names in the style of Steve Jobs, or an image of a business meeting in the style of Van Gogh. When there are clashes between style and format, it’s often best to resolve them by dropping whichever element is less important to your final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide Examples\n",
    "\n",
    "#### The original prompt didn’t give the AI any examples of what you think good names look like. Therefore, the response is approximate to an average of the internet, and you can do better than that. Researchers would call a prompt with no examples zero-shot, and it’s always a pleasant surprise when AI can even do a task zero shot: it’s a sign of a powerful model. If you’re providing zero examples, you’re asking for a lot without giving much in return. Even providing one example (one-shot) helps considerably, and it’s the norm among researchers to test how models perform with multiple examples (few-shot). One such piece of research is the famous GPT-3 paper “Language Models are Few-Shot Learners”, the results of which are illustrated in Figure 1-8, showing adding one example along with a prompt can improve accuracy in some tasks from 10% to near 50%!\n",
    "\n",
    "#### There’s a trade-off between reliability and creativity: go past three to five examples and your results will become more reliable, while sacrificing creativity. The more examples you provide, and the lesser the diversity between them, the more constrained the response will be to match your examples. If you change all of the examples to animal names in the previous prompt, you’ll have a strong effect on the response, which will reliably return only names including animals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
