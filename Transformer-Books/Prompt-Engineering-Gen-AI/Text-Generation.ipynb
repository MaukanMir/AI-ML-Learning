{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction To Large Language Models For Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leveraging Quantization and LoRA\n",
    "\n",
    "#### One of the game-changing aspects of these open source models is the potential for quantization and the use of LoRA (low-rank approximations). These techniques allow developers to fit the models into smaller hardware footprints. Quantization helps to reduce the numerical precision of the model’s parameters, thereby shrinking the overall size of the model without a significant loss in performance. Meanwhile, LoRA assists in optimizing the network’s architecture, making it more efficient to run on consumer-grade hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of Role Prompting\n",
    "\n",
    "#### Role prompting helps narrow down the AI’s responses, ensuring more focused, contextually appropriate, and tailored results. It can also enhance creativity by pushing the AI to think and respond from unique perspectives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges of Role Prompting\n",
    "\n",
    "#### Role prompting can pose certain challenges. There might be potential risks for bias or stereotyping based on the role assigned. Assigning stereotyped roles can lead to generating biased responses, which could harm usability or offend individuals. Additionally, maintaining consistency in the role throughout an extended interaction can be difficult. The model might drift off-topic or respond with information irrelevant to the assigned role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give GPTs “Thinking Time”\n",
    "#### Often, by explicitly guiding an LLM to derive solutions from first principles before reaching a verdict, you can garner more accurate responses. Providing an LLM with thinking time can often lead to better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Inner Monologue Tactic\n",
    "#### The inner monologue tactic instructs the model to structure parts of the output that should be hidden from the user in a specific format. This makes it easy to remove these parts before presenting the final output to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Eval LLM Responses\n",
    "#### Another tactic you can use is to critque a generated LLM output and ask whether the LLM missed any information or important facts. You’re essentially asking an LLM to evaluate itself based on its previous output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
