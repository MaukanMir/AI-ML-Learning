{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Lake Formation\n",
    "### AWS Lake Formation is a comprehensive data management service offered by AWS, which streamlines the process of building and maintaining a data lake on the AWS platform. The following figure illustrates the core components of AWS Lake Formation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data source crawler: \n",
    "- This functionality automatically examines data files within the data lake to infer their underlying structure, enabling efficient organization and categorization of the data.\n",
    "### Data catalog creation and maintenance: \n",
    "- AWS Lake Formation facilitates the creation and ongoing management of a data catalog, providing a centralized repository for metadata, enabling easy data discovery and exploration within the data lake.\n",
    "### Data transformation processing: \n",
    "- With built-in data transformation capabilities, the service allows for the processing and transformation of data stored in the data lake, enabling data scientists and analysts to work with refined and optimized datasets.\n",
    "### Data security and access control: \n",
    "- AWS Lake Formation ensures robust data security by providing comprehensive access control mechanisms and enabling fine-grained permissions management, ensuring that data is accessed only by authorized individuals and teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Ingestion\n",
    "\n",
    "### AWS provides several services for data ingestion into a data lake on their platform. These services include Kinesis Data Streams, Kinesis Firehose, AWS Managed Streaming for Kafka, and AWS Glue Streaming, which cater to streaming data requirements. For batch ingestion, options such as AWS Glue, SFTP, and AWS Data Migration Service (DMS) are available. In the upcoming section, we will delve into the usage of Kinesis Firehose and AWS Glue to manage data ingestion processes for data lakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinesis Firehose\n",
    "\n",
    "### Kinesis Firehose is a service that streamlines the process of loading streaming data into a data lake. It is a fully managed solution, meaning you don’t have to worry about managing the underlying infrastructure. Instead, you can interact with the service’s API to handle the ingestion, processing, and delivery of your data.\n",
    "\n",
    "### Kinesis Firehose provides comprehensive support for various scalable data ingestion requirements, including:\n",
    "\n",
    "- Seamless integration with diverse data sources such as websites, IoT devices, and video cameras. This is achieved using an ingestion agent or ingestion API.\n",
    "- Versatility in delivering data to multiple destinations, including Amazon S3, Amazon Redshift (an AWS data warehouse service), Amazon OpenSearch (a managed search engine), and Splunk (a log aggregation and analysis product).\n",
    "- Seamless integration with AWS Lambda and Kinesis Data Analytics, offering advanced data processing capabilities. With AWS Lambda, you can leverage serverless computing to execute custom functions written in languages like Python, Java, Node.js, Go, C#, and Ruby. For more comprehensive information on the functionality of Lambda, please refer to the official AWS documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Glue\n",
    "### AWS Glue is a comprehensive serverless ETL service that helps manage the data integration and ingestion process for data lakes. It seamlessly connects with various data sources, including transactional databases, data warehouses, and NoSQL databases, facilitating the movement of data to different destinations, such as Amazon S3. This movement can be scheduled or triggered by events. Additionally, AWS Glue offers the capability to process and transform data before delivering it to the target. It provides a range of processing options, such as the Python shell for executing Python scripts and Apache Spark for Spark-based data processing tasks. With AWS Glue, you can efficiently integrate and ingest data into your data lake, benefiting from its fully managed and serverless nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Lambda\n",
    "### AWS Lambda is AWS’s serverless computing platform. It seamlessly integrates with various AWS services, including Amazon S3. By leveraging Lambda, you can trigger the execution of functions in response to events, such as the creation of a new file in S3. These Lambda functions can be developed to move data from different sources, such as copying data from a source S3 bucket to a target landing bucket in a data lake.\n",
    "\n",
    "### It’s important to note that AWS Lambda is not specifically designed for large-scale data movement or processing tasks, due to limitations such as memory size and maximum execution time allowed. However, for simpler data ingestion and processing jobs, it proves to be a highly efficient tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Glue Data Catalog\n",
    "\n",
    "### Automated data discovery: AWS Glue provides automated data discovery capabilities. By using data crawlers, Glue can scan and analyze data from diverse structured and semi-structured sources such as Amazon S3, relational databases, NoSQL databases, and more. It identifies metadata information, including table schemas, column names, and data types, that is stored in the AWS Glue Data Catalog.\n",
    "### Centralized metadata repository: The AWS Glue Data Catalog serves as a centralized metadata repository for your data assets. It provides a unified view of your data, making it easier to search, query, and understand the available datasets.\n",
    "### Metadata management: AWS Glue allows you to manage and maintain metadata associated with your data assets. You can define custom tags, add descriptions, and organize your data using databases, tables, and partitions within the Data Catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Lambda\n",
    "\n",
    "### At a high level, AWS Lambda triggers are used to populate DynamoDB tables with object names and metadata when those objects are put into S3; Amazon OpenSearch Service is used to search for specific assets, related metadata, and data classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let’s examine a selection of AWS services that offer data processing capabilities within a data lake architecture:\n",
    "\n",
    "- AWS Glue ETL: In addition to supporting data movement and data catalogs, the ETL features of AWS Glue can be used for ETL and general-purpose data processing. AWS Glue ETL provides several built-in functions for data transformation, such as dropping the NULL field (the NULL field represents new data) and data filtering. It also provides general processing frameworks for Python and Spark to run Python scripts and Spark jobs. Glue ETL works natively with the AWS Glue Data Catalog to access the databases and tables in the catalog. Glue ETL can also access the Amazon S3 storage directly.\n",
    "\n",
    "- Amazon Elastic MapReduce (EMR): Amazon EMR is a fully managed big data processing platform on AWS. It is designed for large-scale data processing using the Spark framework and other Apache tools, such as Apache Hive, Apache Hudi, and Presto. It integrates with the Glue Data Catalog and Lake Formation natively to access databases and tables in Lake Formation.\n",
    "\n",
    "- AWS Lambda: AWS Lambda can be used for lightweight data processing tasks or as part of a larger data processing pipeline within the data lake architecture. Lambda can be triggered by real-time events, so it is a good option for real-time data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioned S3 buckets\n",
    "### Amazon S3 offers versioning support for S3 buckets, which can be leveraged to manage different versions of training datasets when enabled. With this approach, each newly created or updated dataset is assigned a unique version ID at the S3 object level. Additionally, it is recommended to utilize a database to store all relevant metadata associated with each version of the training dataset. This enables the establishment of lineage, tracking the journey from data processing to ML model training. The metadata should capture essential information to facilitate comprehensive tracking and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
