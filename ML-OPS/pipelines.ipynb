{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With MLOps, ML teams build machine learning pipelines that automatically collect and prepare data, select optimal features, run training using different parameter sets or algorithms, evaluate models, and run various model and system tests. All the executions, along with their data, metadata, code, and results, must be versioned and logged, providing quick results visualization, comparing them with past results, and understanding which data was used to produce each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML pipelines can be started manually or (preferably) triggered automatically when:\n",
    "\n",
    "- The code, packages, or parameters change.\n",
    "\n",
    "- The input data or feature engineering logic change.\n",
    "\n",
    "- Concept drift is detected, and the model needs to be retrained with fresh data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML pipelines have the following features:\n",
    "\n",
    "- Built using microservices (containers or serverless functions), usually over Kubernetes.\n",
    "\n",
    "- Track all their inputs (code, package dependencies, data, parameters) and the outputs (logs, metrics, data/features, artifacts, models) for every step in the pipeline in order to reproduce or explain experiment results.\n",
    "\n",
    "- Version all the data and artifacts used throughout the pipeline.\n",
    "\n",
    "- Store code and configuration in versioned Git repositories.\n",
    "\n",
    "- Use CI techniques to automate the pipeline initiation, test automation, review, and approval process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines should be executed over scalable services or functions, which can span elastically over multiple servers or containers. This way, jobs complete faster, and computation resources are freed up once they are complete, saving high costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can find projects where the data preparation, training, evaluation, and even prediction are all made in one huge Notebook, but this approach can lead to challenges when moving to production, for example:\n",
    "\n",
    "- Very hard to track the code changes across versions (in Git).\n",
    "\n",
    "- Almost impossible to implement test harnesses and unit testing.\n",
    "\n",
    "- Functions cannot be reused in various projects.\n",
    "\n",
    "- Moving to production requires code refactoring and removal of visualization or scratch code.\n",
    "\n",
    "- Lack of proper documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
