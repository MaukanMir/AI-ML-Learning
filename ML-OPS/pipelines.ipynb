{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With MLOps, ML teams build machine learning pipelines that automatically collect and prepare data, select optimal features, run training using different parameter sets or algorithms, evaluate models, and run various model and system tests. All the executions, along with their data, metadata, code, and results, must be versioned and logged, providing quick results visualization, comparing them with past results, and understanding which data was used to produce each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML pipelines can be started manually or (preferably) triggered automatically when:\n",
    "\n",
    "- The code, packages, or parameters change.\n",
    "\n",
    "- The input data or feature engineering logic change.\n",
    "\n",
    "- Concept drift is detected, and the model needs to be retrained with fresh data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML pipelines have the following features:\n",
    "\n",
    "- Built using microservices (containers or serverless functions), usually over Kubernetes.\n",
    "\n",
    "- Track all their inputs (code, package dependencies, data, parameters) and the outputs (logs, metrics, data/features, artifacts, models) for every step in the pipeline in order to reproduce or explain experiment results.\n",
    "\n",
    "- Version all the data and artifacts used throughout the pipeline.\n",
    "\n",
    "- Store code and configuration in versioned Git repositories.\n",
    "\n",
    "- Use CI techniques to automate the pipeline initiation, test automation, review, and approval process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines should be executed over scalable services or functions, which can span elastically over multiple servers or containers. This way, jobs complete faster, and computation resources are freed up once they are complete, saving high costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can find projects where the data preparation, training, evaluation, and even prediction are all made in one huge Notebook, but this approach can lead to challenges when moving to production, for example:\n",
    "\n",
    "- Very hard to track the code changes across versions (in Git).\n",
    "\n",
    "- Almost impossible to implement test harnesses and unit testing.\n",
    "\n",
    "- Functions cannot be reused in various projects.\n",
    "\n",
    "- Moving to production requires code refactoring and removal of visualization or scratch code.\n",
    "\n",
    "- Lack of proper documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality tests\n",
    "- The dataset used for training is of high quality and does not carry bias.\n",
    "\n",
    "### Model performance tests\n",
    "- The model produces accurate results.\n",
    "\n",
    "### Serving application tests\n",
    "- The deployed model along with the data pre- or post-processing steps are robust and provide adequate performance.\n",
    "\n",
    "### Pipeline tests\n",
    "- Ensuring the automated development pipeline handles various exceptions and the desired scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here are some examples of data quality tests:\n",
    "\n",
    "- There are no missing values.\n",
    "\n",
    "- Values are of the correct type and fall under an expected range (for example, user age is between 0-120, with anticipated average and standard deviation).\n",
    "\n",
    "- Category values fall within the possible options (for example, city names match the options in a city name list).\n",
    "\n",
    "- There is no bias in the data (for example, the gender feature has the anticipated percentage of men and women)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
