{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With MLOps, ML teams build machine learning pipelines that automatically collect and prepare data, select optimal features, run training using different parameter sets or algorithms, evaluate models, and run various model and system tests. All the executions, along with their data, metadata, code, and results, must be versioned and logged, providing quick results visualization, comparing them with past results, and understanding which data was used to produce each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML pipelines can be started manually or (preferably) triggered automatically when:\n",
    "\n",
    "- The code, packages, or parameters change.\n",
    "\n",
    "- The input data or feature engineering logic change.\n",
    "\n",
    "- Concept drift is detected, and the model needs to be retrained with fresh data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML pipelines have the following features:\n",
    "\n",
    "- Built using microservices (containers or serverless functions), usually over Kubernetes.\n",
    "\n",
    "- Track all their inputs (code, package dependencies, data, parameters) and the outputs (logs, metrics, data/features, artifacts, models) for every step in the pipeline in order to reproduce or explain experiment results.\n",
    "\n",
    "- Version all the data and artifacts used throughout the pipeline.\n",
    "\n",
    "- Store code and configuration in versioned Git repositories.\n",
    "\n",
    "- Use CI techniques to automate the pipeline initiation, test automation, review, and approval process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
