{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is the ability to dynamically highlight and use the salient parts of the information at hand — in a similar manner as it does in the human brain — that makes attention such an attractive concept in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Think of an attention-based system consisting of three components:\n",
    "1. A process that “reads” raw data(such as source words in a source sentence), and converts them into distributed representations, with one feature vector associated with each word position.\n",
    "2. A list of feature vectors storing the output of the reader. This can be understood as a “memory” containing a sequence of facts, which can be retrieved later, not necessarily in the same order, without having to visit all of them.\n",
    "3. A process that “exploits” the content of the memory to sequentially perform\n",
    "a task, at each time step having the ability put attention on the content\n",
    "of one memory element (or a few, with a different weight)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let’s take the encoder-decoder framework as an example since it is within such a framework that the attention mechanism was first introduced. If we are processing an input sequence of words, then this will first be fed into an encoder, which will output a vector for every element in the sequence. This corresponds to the first component of our attention-based system, as explained above. A list of these vectors (the second component of the attention-based system above), together with the decoder’s previous hidden states, will be exploited by the attention mechanism to dynamically highlight which of the input information will be used to generate the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At each time step, the attention mechanism then takes the previous hidden state of the decoder and the list of encoded vectors, using them to generate unnormalized score values that indicate how well the elements of the input sequence align with the current output. Since the generated score values need to make relative sense in terms of their importance, they are normalized by passing them through a softmax function to generate the weights. Following the softmax normalization, all the weight values will lie in the interval [0, 1] and add up to 1, meaning they can be interpreted as probabilities. Finally, the encoded vectors are scaled by the computed weights to generate a context vector. This attention process forms the third component of the attention-based system above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The idea is to be able to work with an artificial neural network that can perform well on tasks where the input may be of variable length, size, or structure or even handle several different tasks. It is in this spirit that attention mechanisms in machine learning are said to inspire themselves from psychology rather than because they replicate the biology of the human brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The task of the encoder is to generate a vector representation of the input, whereas the task of the decoder is to transform this vector representation into an output. The attention mechanism connects the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention helpd determine which of these vectors should be used to generate the output. Because the output sequence is dynamically generated one element at a time, atttention can dynamically highlight different encoded vectors at each time point. This allows the decoder to flexibly utilize the most relevant parts of the input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More recently, Vaswani et al. (2017) proposed an entirely different architecture that has steered the field of machine translation in a new direction. Termed transformer, their architecture dispenses with any recurrence and convolutions altogether but implements a self- attention mechanism. Words in the source sequence are first encoded in parallel to generate key, query, and value representations. The keys and queries are combined to generate attention weightings that capture how each word relates to the others in the sequence. These attention weightings are then used to scale the values, in order to retain focus on the important words and drown out the irrelevant ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The self-attention mechanism relies on the use of queries, keys, and values, which are generated by multiplying the encoder’s representation of the same input sequence with different weight matrices. The transformer uses dot product (or multiplicative) attention, where each query is matched against a database of keys by a dot product operation in the process of generating the attention weights. These weights are then multiplied by the values to generate a final attention vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bahdanau Architecture\n",
    "\n",
    "### For this purpose, Bahdanau et al. employ a bidirectional RNN, which reads the input sentence in the forward direction to produce a forward hidden state −!h i, and then reads the input sentence in the reverse direction to produce a backward hidden state h− . The annotation for some particular word xi concatenates the two states: i\n",
    "\n",
    "### The idea behind generating each annotation in this manner was to capture a summary of both the preceding and succeeding words\n",
    "\n",
    "### The generated annotations are then passed to the decoder to generate the context vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Decoder\n",
    "\n",
    "### The role of the decoder is to produce the target words by focusing on the most relevant information contained in the source sentence. For this purpose, it makes use of an attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luong Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The global attentional model resembles the Bahdanau et al. (2015) model in attending to all source words but aims to simplify it architecturally. The local attentional model is inspired by the hard and soft attention models of Xu et al. (2015) and attends to only a few of the source positions. The two attentional models share many of the steps in their prediction of the current word but differ mainly in their computation of the context vector. Let’s first take a look at the overarching Luong attention algorithm and then delve into the differences between the global and local attentional models afterward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The General Attention Mechanism\n",
    "\n",
    "### The general attention mechanism makes use of three main components, namely the queries Q, the keys K, and the values V.\n",
    "- If you had to compare these three components to the attention mechanism as proposed by Bahdanau et al., then the query would be analogous to the previous decoder output st−1, while the values would be analogous to the encoded inputs hi. In the Bahdanau attention mechhanism, the keys and the values are the same vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within the context of machine translation, each word in an input sentence would be attributed its own query, key and value vectors. These vectors are generated by multiplying the encoder’s representation of the specific word under consideration with three different weight matrices that would have been generated during training.\n",
    "### In essence, when the generalized attention mechanism is presented with a sequence of words, it takes the query vector attributed to some specific word in the sequence and scores it against each key in the database. In doing so, it captures how the word under consideration relates to the others in the sequence. Then it scales the values according to the attention weights (computed from the scores) to retain focus on those words relevant to the query. In doing so, it produces an attention output for the word under consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The positional encoding vectors are of the same dimension as the input embeddings and are generated using sine and cosine functions of different frequencies. Then, they are simply summed to the input embeddings in order to inject the positional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional encoding is the scheme through which the knowledge of order of objects in a sequence is maintained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "### X = number of tokens X token dimesnion\n",
    "\n",
    "### We perform three linear transformations on the matrix X to project it onto three new vector spaces called the:\n",
    "- Query space\n",
    "- Key Space\n",
    "-  Value space\n",
    "\n",
    "\n",
    "### Lets say we have a  4 by 2 matrix\n",
    "- We perform three linear transformations using the dot product\n",
    "- This creates W^Q, W^K, W^V matrices which are 3 by 4 matrices\n",
    "- Finally another linear transformation creates a 3 by 3 matrix for our example of an initial 4 by 2 matrix\n",
    "\n",
    "### Attention scores are then created\n",
    "- Smaller values meant vectors were not close and therefore less attention in score\n",
    "- Larger values meant vectors were close and therefore more attention\n",
    "\n",
    "### Next \n",
    "- We divide by the number of square root of the number of dimensions \n",
    "- Then apply the soft max function which creates a probability disttribution which adds up to 1 which maintains order. This represents the confidence level of each token by probability %\n",
    "- Then we multiply these values by the value of each token\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
