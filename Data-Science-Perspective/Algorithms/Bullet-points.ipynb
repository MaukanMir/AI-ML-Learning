{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFC\n",
    "\n",
    "#### Key advantages of a Random Forest classifier include:\n",
    "\n",
    "- Robustness: It is one of the most robust models available. Random Forests handle outliers, skewed data, and non-linear data effectively.\n",
    "- High Accuracy: It generally provides a high level of accuracy in classification tasks because it mitigates the overfitting problem of decision trees.\n",
    "- Feature Importance: It is very handy to get a sense of which features are contributing most to the outcome, as Random Forest can provide an estimate of what variables are important in the classification.\n",
    "- Versatility: It can be used for both classification and regression tasks, and it handles multi-output problems as well.\n",
    "- Ease of Use: It requires very little tuning of the model parameters and can be quite robust to noise from the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fundamental steps in creating a Random Forest model are:\n",
    "\n",
    "- Randomly select 'k' features from total 'm' featuresâ€”where k<<m. Among the 'k' features, calculate the node 'd' using the best split point based on the criterion like Gini impurity or entropy in classification problems Split the node into daughter nodes using the best split. \n",
    "- Repeat the steps of feature selection and node splitting until a specified number of nodes has been reached, or until the node has fewer than a minimum number of points. \n",
    "- Build forest by repeating steps 1 to 3 for 'n' times to create 'n' number of trees.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
