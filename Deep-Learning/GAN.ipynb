{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator and discriminator. First, we should have a reasonable sample of images of an object. A generative network (generator) learns representation from a sample of images and then generates images similar to the sample of images. A discriminator network (discriminator) is one that looks at the image generated (by the generator network) and the original sample of images and classifies images as original ones or generated (fake) ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the generator (and not the discriminator) to generate images such that the discriminator classifies the images as real.\n",
    "- Train the discriminator (and not the generator) to classify the images that the generator generates as fake.\n",
    "- Repeat the process until an equilibrium is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_train_step(real_data, fake_data):\n",
    "    d_optimizer.zero_grad()\n",
    "    prediction_real = discriminator(real_data)\n",
    "    error_real = loss(prediction_real.squeeze(), \\\n",
    "                      torch.ones(len(real_data)).to(device))\n",
    "    error_real.backward()\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    error_fake = loss(prediction_fake.squeeze(), \\\n",
    "                      torch.zeros(len(fake_data)).to(device))\n",
    "    error_fake.backward()\n",
    "    d_optimizer.step()\n",
    "    return error_real + error_fake\n",
    "\n",
    "def generator_train_step(fake_data):\n",
    "    g_optimizer.zero_grad()\n",
    "    prediction = discriminator(fake_data)\n",
    "    error = loss(prediction.squeeze(), \\\n",
    "                 torch.ones(len(real_data)).to(device))\n",
    "    error.backward()\n",
    "    g_optimizer.step()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing conditional GANs\n",
    "\n",
    "### The strategy we adopt is as follows:\n",
    "\n",
    "- Specify the label of the image we want to generate as a one-hot-encoded version.\n",
    "- Pass the label through an embedding layer to generate a multi-dimensional representation of each class.\n",
    "- Generate random noise and concatenate with the embedding layer generated in the previous step.\n",
    "- Train the model just like we did in the previous sections, but this time with the noise vector concatenated with the embedding of the class of image we wish to generate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
