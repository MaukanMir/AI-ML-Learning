{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking Probabilistically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood\n",
    "\n",
    "#### The likelihood is how we will introduce data in our analysis. It is an expression of the plausibility of the data given the parameters. In some texts, you will find people call this term sampling model, statistical model, or just model. We will stick to the name likelihood and we will model the combination of priors and likelihood.\n",
    "\n",
    "## Prior Distribution\n",
    "\n",
    "#### The prior distribution should reflect what we know about the value of the parameter θ before seeing the data, Y \n",
    "\n",
    "## Posterior Distribution\n",
    "\n",
    "#### The posterior distribution is the result of the Bayesian analysis and reflects all that we know about a problem (given our data and model). The posterior is a probability distribution for the parameters in our model and not a single value. \n",
    "\n",
    "## Marginal Likelihood\n",
    "\n",
    "#### The last term is the marginal likelihood, sometimes referred to as the evidence. Formally, the marginal likelihood is the probability of observing the data averaged over all the possible values the parameters can take (as prescribed by the prior). We can write this as ∫ Θp(Y |θ)p(θ)dθ. We will not really care about the marginal likelihood until Chapter 5. But for the moment, we can think of it as a normalization factor that ensures the posterior is a proper pmf or pdf. If we ignore the marginal likelihood, we can write Bayes’ theorem as a proportionality, which is also a common way to write Bayes’ theorem:\n",
    "\n",
    "- p(θ | Y ) ∝ p(Y | θ)p(θ) \n",
    "\n",
    "\n",
    "- The result of a Bayesian analysis is a posterior distribution – not a single value but a distribution of plausible values given the data and our model.\n",
    "\n",
    "- The most probable value is given by the mode of the posterior (the peak of the distribution).\n",
    "\n",
    "- The spread of the posterior is proportional to the uncertainty about the value of a parameter; the more spread out the distribution, the less certain we are."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
