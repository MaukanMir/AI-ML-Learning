{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to solve Bayes Theorem\n",
    "\n",
    "- Calculate Hypothesis\n",
    "- Calculate Prior probabilities\n",
    "- Calculate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.3.9\n",
    "\n",
    "#### (Testing for a rare disease). A patient named Fred is tested for a disease called conditionitis, a medical condition that afflicts 1% of the population. The test result is positive, i.e., the test claims that Fred has the disease. Let D be the event that Fred has the disease and T be the event that he tests positive.\n",
    "#### Suppose that the test is “95% accurate”; there are different measures of the accuracy of a test, but in this problem it is assumed to mean that P(T|D) = 0.95 and P(Tc|Dc) = 0.95. The quantity P(T|D) is known as the sensitivity or true positive rate of the test, and P(Tc|Dc) is known as the specificity or true negative rate.\n",
    "\n",
    "- D = Affects 0.01% of the population\n",
    "- P(H) = 0.01\n",
    "- P(T|D) = 0.95% accurate \n",
    "- Numerator =  P(T|D) * P(D) = 0.95 * 0.01 = 0.0095\n",
    "- Denominator = (0.05 * 0.99) + (0.95 * 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16101694915254236\n"
     ]
    }
   ],
   "source": [
    "test = 0.95\n",
    "disease = 0.01\n",
    "numerator = 0.95 * 0.01\n",
    "denominator = (0.05 * 0.99) + (0.95 * 0.01)\n",
    "\n",
    "print(numerator/denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The key to understanding this surprisingly high posterior probability is to realize that there are two factors at play: the evidence from the test, and our prior information about the prevalence of the disease. Although the test provides evidence in favor of disease, conditionitis is also a rare condition! The conditional probability P(D|T) reflects a balance between these two factors, appropriately weighing the rarity of the disease against the rarity of a mistaken test result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional probabilities are probabilities, and all probabilities are conditional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independence of Events\n",
    "\n",
    "#### In words, two events are independent if we can obtain the probability of their intersection by multiplying their individual probabilities. Alternatively, A and B are independent if learning that B occurred gives us no information that would change our probabilities for A occurring (and vice versa).\n",
    "\n",
    "- Note that independence is a symmetric relation: if A is independent of B, then B is independent of A.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Coherency of Bayes’ rule\n",
    "\n",
    "#### An important property of Bayes’ rule is that it is coherent : if we receive multiple pieces of information and wish to update our probabilities to incorporate all the information, it does not matter whether we update sequentially, taking each piece of evidence into account one at a time, or simultaneously, using all the evidence at once. Suppose, for example, that we’re conducting a weeklong experiment that yields data at the end of each day. We could use Bayes’ rule every day to update our probabilities based on the data from that day. Or we could go on vacation for the week, come back on Friday afternoon, and update using the entire week’s worth of data. Either method will give the same result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: A spam filter is designed by looking at commonly occurring phrases in spam. Suppose that 80% of email is spam. In 10% of the spam emails, the phrase “free money” is used, whereas this phrase is only used in 1% of non-spam emails. A new email has just arrived, which does mention “free money”. What is the probability that it is spam?\n",
    "\n",
    "\n",
    "#### Problem Breakdown:\n",
    "- P(S) = 0.8\n",
    "- P( S| free money is in the email) = 0.10\n",
    "- P(Not Spam) = 0.20\n",
    "- P(Not Spam | Free money is in the email) = 0.001\n",
    "\n",
    "What is P(Spam | \"Free Money\" is in the email)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
