{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random variables and their distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Thus, a random variable X assigns a numerical value X(s) to each possible outcome s of the experiment. The randomness comes from the fact that we have a random experiment (with probabilities described by the probability function P); the mapping itself is deterministic,\n",
    "\n",
    "![Sample Image](/Users/maukanmir/Documents/Machine-Learning/AI-ML-Textbooks/AI-ML-Learning/images/random-var.png)\n",
    "\n",
    "#### A random variable maps the sample space into the real line. The r.v. X depicted here is defined on a sample space with 6 elements, and has possible values 0, 1, and 4. The randomness comes from choosing a random pebble according to the probability function P for the sample space.\n",
    "\n",
    "##### This definition is abstract but fundamental; one of the most important skills to develop when studying probability and statistics is the ability to go back and forth between abstract ideas and concrete examples. Relatedly, it is important to work on recognizing the essential pattern or structure of a problem and how it connects to problems you have studied previously. We will often discuss stories that involve tossing coins or drawing balls from urns because they are simple, convenient scenarios to work with, but many other problems are isomorphic: they have the same essential structure, but in a different guise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli and Binomial\n",
    "\n",
    "#### (Bernoulli distribution). An r.v. X is said to have the Bernoulli distribution with parameter p if P (X = 1) = p and P (X = 0) = 1 ‚àí p, where 0 < p < 1. We write this as X ~ Bern(p). The symbol ~ is read ‚Äúis distributed as‚Äù.\n",
    "\n",
    "#### Any r.v. whose possible values are 0 and 1 has a Bern(p) distribution, with p the probability of the r.v. equaling 1. This number p in Bern(p) is called the parameter of the distribution; it determines which specific Bernoulli distribution we have. Thus there is not just one Bernoulli distribution, but rather a family of Bernoulli distributions, indexed by p. For example, if X ~ Bern(1/3), it would be correct but incomplete to say ‚ÄúX is Bernoulli‚Äù; to fully specify the distribution of X, we should both say its name (Bernoulli) and its parameter value (1/3), which is the point of the notation X ~ Bern(1/3).\n",
    "\n",
    "#### (Bernoulli trial). An experiment that can result in either a ‚Äúsuccess‚Äù or a ‚Äúfailure‚Äù (but not both) is called a Bernoulli trial. A Bernoulli random variable can be thought of as the indicator of success in a Bernoulli trial: it equals 1 if success occurs and 0 if failure occurs in the trial.\n",
    "\n",
    "#### Because of this story, the parameter p is often called the success probability of the Bern(p) distribution. Once we start thinking about Bernoulli trials, it‚Äôs hard not to start thinking about what happens when we have more than one Bernoulli trial.\n",
    "\n",
    "## Binomial\n",
    "#### (Binomial distribution). Suppose that n independent Bernoulli trials are performed, each with the same success probability p. Let X be the number of successes. The distribution of X is called the Binomial distribution with parameters n and p. We write X ~ Bin(n, p) to mean that X has the Binomial distribution with parameters n and p, where n is a positive integer and 0 < p < 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXample 3.7.2\n",
    "\n",
    "#### (Random walk). A particle moves n steps on a number line. The particle starts at 0, and at each step it moves 1 unit to the right or to the left, with equal probabilities. Assume all steps are independent. Let Y be the particle‚Äôs position after n steps. Find the PMF of Y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Y = -10) = 0.0010\n",
      "P(Y = -8) = 0.0098\n",
      "P(Y = -6) = 0.0439\n",
      "P(Y = -4) = 0.1172\n",
      "P(Y = -2) = 0.2051\n",
      "P(Y = 0) = 0.2461\n",
      "P(Y = 2) = 0.2051\n",
      "P(Y = 4) = 0.1172\n",
      "P(Y = 6) = 0.0439\n",
      "P(Y = 8) = 0.0098\n",
      "P(Y = 10) = 0.0010\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import comb\n",
    "import numpy as np\n",
    "\n",
    "def random_walk_pmf(n):\n",
    "    # Dictionary to store the PMF\n",
    "    pmf = {}\n",
    "    \n",
    "    # Loop over all possible end positions y from -n to n with step size 2\n",
    "    for y in range(-n, n+1, 2):\n",
    "        k = (y + n) // 2  # Number of steps to the right\n",
    "        \n",
    "        # Check if y+n is even and k is within the valid range\n",
    "        if (y + n) % 2 == 0 and 0 <= k <= n:\n",
    "            pmf[y] = comb(n, k) * (0.5**n)  # Calculate PMF using the binomial coefficient\n",
    "            \n",
    "    return pmf\n",
    "\n",
    "# Example usage\n",
    "n_steps = 10  # Number of steps in the random walk\n",
    "pmf_result = random_walk_pmf(n_steps)\n",
    "\n",
    "# Print the results\n",
    "for position, probability in pmf_result.items():\n",
    "    print(f'P(Y = {position}) = {probability:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (a) Independent Bernoulli trials are performed, with probability 1/2 of success, until there has been at least one success. Find the PMF of the number of trials performed.\n",
    "\n",
    "- K is the trial number on which the first success occurs\n",
    "- p is the probability of success on each trial,\n",
    "- (1-p)^k-1 is the probabaility of having k-1 failures before the first success\n",
    "\n",
    "- P(X=k) = (1-p)^k-1 x p\n",
    "\n",
    "- P(X=k) = (1/2)^k-1 * 1/2\n",
    "- P(X=k) = 1/2^k\n",
    "- For k = 1,2,3 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Distribution\n",
    "#### The geometric distribution is used to model the number of trials until the first success in a sequence of independent Bernoulli trials, where each trial has a constant probability of success. The key characteristic of the geometric distribution is that it describes the trials up to and including the first success.\n",
    "\n",
    "#### One of the unique features of the geometric distribution is its memoryless property. This means that the probability of achieving the first success in future trials does not depend on how many trials have already been performed without success. Mathematically, this can be expressed as:\n",
    "- P(X > n +k | X > n) = P(X > k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Independent Bernoulli trials are performed, with probability 1/2 of success, until there has been at least one success and at least one failure. Find the PMF of the number of trials performed.\n",
    "\n",
    "#### For either case, if the first outcome occurs on the first trial, the subsequent trials follow a geometric distribution (with p =1/2) for the opposite event.\n",
    "- The probability of stopping after k trials k >= 2 is determined by P(X=K) = (1/2) * (1/2)^k-1 + (1/2) * (1/2)^k-1\n",
    "- 2 * (1/2)^k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Logarithms\n",
    "\n",
    "#### A logarithm asks the question: To what power must a given base b be raised to produce a certain number x?\n",
    "\n",
    "#### Formally, if ùëè^ùë¶ =ùë• then log subscript b(x) = y. Here, b is the base of the algorithm, x is the argument and y is the logarithm of x to base b."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
